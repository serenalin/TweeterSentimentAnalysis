{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDMDRLOHtES8"
   },
   "source": [
    "# Tweeter Sentiment Analysis\n",
    "\n",
    "Perform [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) of Twitter data&mdash;that is, determining the \"attitude\" or \"emotion\" (e.g., how \"positive\", \"negative\", \"joyful\", etc) of tweets made by a particular Twitter user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tweet data taken directly from [Twitter's API](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline). \n",
    "\n",
    "We'll use a set of **word-sentiments**&mdash;a list of English-language words and what emotions (e.g., \"joy\", \"anger\") [are associated with them](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm).\n",
    "\n",
    "* The [`nltk`](https://github.com/nltk/nltk/wiki/Sentiment-Analysis) library also support sentiment analysis. However, for practice and extendability, we'll doing a more \"manual\" analysis using the provided data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a set of word-sentiments, a list of English-language words and what emotions are associated with them.\n",
    "from data.sentiments_nrc import SENTIMENTS, EMOTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MGEMu0BtETC"
   },
   "source": [
    "## Text Sentiment\n",
    "Define a function that take a tweet's text (a string) and split it up into a list of individual words. For example, the string `\"Amazingly, I prefer a #rainy day to #sunshine.\"` should produce a list with 6 lower-case words in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BmvevEDtETD",
    "outputId": "eff85008-d234-42ca-896c-909934b7998b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazingly', 'prefer', 'rainy', 'day', 'to', 'sunshine']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function that take a tweet's text (a string) and split it up into a list of individual words\n",
    "def split_words(text):\n",
    "    \"\"\"Take in a string as \"text\", then transform the string into lower case, split up and store into a list(split_text)\"\"\"\n",
    "    import re\n",
    "    text = text.lower()\n",
    "    split_text = re.split(r'\\W+',text)\n",
    "    for words in split_text:\n",
    "        if len(words) <=1:\n",
    "            split_text.remove(words)\n",
    "    return(split_text)\n",
    "split_words(\"Amazingly, I prefer a #rainy day to #sunshine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQkOkljFtETF"
   },
   "source": [
    "Define a function that **filters** a list of the words to get only those words that contain a specific emotion. For example, the `\"positive\"` words extracted from `\"Amazingly, I prefer a #rainy day to #sunshine.\"` are `[\"amazingly\", \"prefer\", \"sunshine\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zS8fnzHVtETG",
    "outputId": "bd74537f-2b61-47a7-aeb0-feae61c25274"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazingly', 'prefer', 'rainy', 'sunshine']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function that filters a list of the words to get only those words that contain a specific emotion.\n",
    "def filter_emotions(text):\n",
    "    \"\"\"Take in a list of text and filter out words without sentiments. Output sentiments words as a list(emotions_text)\"\"\"\n",
    "    emotions_text = []\n",
    "    for words in text:\n",
    "        if SENTIMENTS.get(words,\"n\") != \"n\":\n",
    "            emotions_text.append(words)\n",
    "    return(emotions_text)\n",
    "filter_emotions(split_words(\"Amazingly, I prefer a #rainy day to #sunshine.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ho929o0PtETI"
   },
   "source": [
    "Define a function that determines which words from a list have _each_ emotion (i.e., the \"emotional\" words). For example, the words extracted from `\"Amazingly, I prefer a #rainy day to #sunshine.\"` should produce a dictionary that looks like:\n",
    "\n",
    "```\n",
    "{\n",
    " 'anger': [],\n",
    " 'anticipation': [],\n",
    " 'disgust': [],\n",
    " 'fear': [],\n",
    " 'joy': ['amazingly', 'sunshine'],\n",
    " 'negative': [],\n",
    " 'positive': ['amazingly', 'prefer', 'sunshine'],\n",
    " 'sadness': ['rainy'],\n",
    " 'surprise': ['amazingly'],\n",
    " 'trust': ['prefer']\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tw4EKayztETJ",
    "outputId": "5df99a87-1ca3-4ce6-a0e8-92befc12bb10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': [],\n",
       " 'anticipation': [],\n",
       " 'disgust': [],\n",
       " 'fear': [],\n",
       " 'joy': ['amazingly', 'sunshine'],\n",
       " 'negative': [],\n",
       " 'positive': ['amazingly', 'prefer', 'sunshine'],\n",
       " 'sadness': ['rainy'],\n",
       " 'surprise': ['amazingly'],\n",
       " 'trust': ['prefer']}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotions_sort(text):\n",
    "    \"\"\"Take in a list of text that contain sentiments, and output a dictionary categorizing words with associated emotions.\"\"\"\n",
    "    emotions_text = filter_emotions(text)\n",
    "    emotions_dict = {}\n",
    "    for i in sorted(EMOTIONS):\n",
    "        emotions_dict[i]=[]\n",
    "    for words in emotions_text:\n",
    "        for i in SENTIMENTS.get(words):\n",
    "            emotions_dict[i].append(words)\n",
    "    return(emotions_dict)\n",
    "emotions_sort(split_words(\"Amazingly, I prefer a #rainy day to #sunshine.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8XeqBVCAtETL"
   },
   "source": [
    "Define a function that gets a list of the \"most common\" words in a list: that is a new list containing each word in the original list, in descending order by how many times that word appears in the orignal list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ee0pP-UtETL",
    "outputId": "71229a51-89ea-4543-86c1-6e016f0a7751"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c', 'a', 'b']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_common(wordlist):\n",
    "    \"\"\"Take in a list of words and find the top 3 common words in the list. Output as a list(most_common)\"\"\"\n",
    "    text_count = {}\n",
    "    for words in wordlist:\n",
    "        prev = text_count.get(words,0)\n",
    "        text_count[words] = prev + 1\n",
    "    text_count_list = []\n",
    "    for i in text_count:\n",
    "        text_count_list.append((i,text_count[i]))\n",
    "    text_count_list = sorted(text_count_list, key=lambda count:count[1], reverse=True)\n",
    "#     In order to make it easier to use in the following functions, transform the tuples into list of common words. \n",
    "    most_common = []\n",
    "    for a in text_count_list:\n",
    "        most_common.append(a[0])\n",
    "    return(most_common)\n",
    "most_common(['a','b','c','c','c','a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuOsxsZ9tETN"
   },
   "source": [
    "## Tweet Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1g9HFzm5tETO"
   },
   "source": [
    "Define a function (e.g., `analyze_tweets()`) that takes as an argument a **list** of tweet data (with the same structure as the imported `SAMPLE_TWEETS` variable), and _returns_ the data of interest to display in a table like the one at the very top of the notebook. In particular, we'll produce the following information **for each emotion**:\n",
    "\n",
    "1. The percentage of words _across all tweets_ that have that emotion\n",
    "2. The most common words _across all tweets_ that have that emotion (in order!)\n",
    "3. The most common **hashtags** _across all tweets_ associated with that emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQQvgClHtETO",
    "outputId": "6d7864a1-338c-4efc-e8b5-3eb43379cf9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('positive', 6.72),\n",
       "  ('trust', 3.36),\n",
       "  ('anticipation', 2.76),\n",
       "  ('joy', 1.92),\n",
       "  ('surprise', 1.08),\n",
       "  ('negative', 0.96),\n",
       "  ('sadness', 0.6),\n",
       "  ('disgust', 0.48),\n",
       "  ('fear', 0.48),\n",
       "  ('anger', 0.36)],\n",
       " {'positive': ['learn', 'faculty', 'happy'],\n",
       "  'negative': ['fall', 'rejection', 'outstanding'],\n",
       "  'anger': ['rejection', 'disaster', 'involvement'],\n",
       "  'anticipation': ['happy', 'top', 'ready'],\n",
       "  'disgust': ['rejection', 'weird', 'finally'],\n",
       "  'fear': ['rejection', 'surprise', 'problem'],\n",
       "  'joy': ['happy', 'peace', 'deal'],\n",
       "  'sadness': ['fall', 'rejection', 'problem'],\n",
       "  'surprise': ['deal', 'award', 'surprised'],\n",
       "  'trust': ['school', 'faculty', 'happy']},\n",
       " {'positive': ['accesstoinfoday', 'indigenouspeoplesday', 'idealistfair'],\n",
       "  'negative': [],\n",
       "  'anger': ['mlis'],\n",
       "  'anticipation': ['indigenouspeoplesday', 'informatics', 'info340'],\n",
       "  'disgust': [],\n",
       "  'fear': [],\n",
       "  'joy': ['indigenouspeoplesday', 'accesstoinfoday'],\n",
       "  'sadness': [],\n",
       "  'surprise': ['suzzallolibrary', 'nobrainer'],\n",
       "  'trust': ['indigenouspeoplesday', 'diversity']})"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_tweets(tweet):\n",
    "    \"\"\"Take in a list of tweet data and output the percentages of sentiments words, most common words and hashtags associated with that emotion.\"\"\"\n",
    "    import re\n",
    "    from functools import reduce\n",
    "    # Create a dictionary to store emotion words and hashtags based on the sentiments associated.\n",
    "    emotions_dict = {'anger': [], 'anticipation': [], 'disgust': [], 'fear': [], 'joy': [], 'negative': [], 'positive': [], 'sadness': [], 'surprise': [], 'trust': []}\n",
    "    hashtags_dict = {'anger': [], 'anticipation': [], 'disgust': [], 'fear': [], 'joy': [], 'negative': [], 'positive': [], 'sadness': [], 'surprise': [], 'trust': []}\n",
    "    for i in range(len(tweet)):\n",
    "        split_text = re.split(\" \",tweet[i]['text'])\n",
    "        # Create keys in the orignal data to store the value of each analysis, including split text, number of words in each tweet, emotions associated, and hashtags.\n",
    "        tweet[i]['split_text'] = split_text\n",
    "        tweet[i]['word_cnt'] = len(split_text)\n",
    "        tweet[i]['emotions'] = emotions_sort(split_words(tweet[i]['text']))\n",
    "        tweet[i]['hashtags'] = []\n",
    "        for a in range(len(tweet[i]['entities']['hashtags'])):\n",
    "            tweet[i]['hashtags'].append(tweet[i]['entities']['hashtags'][a]['text'].lower())\n",
    "        for emotion in emotions_dict:\n",
    "            emotions_dict[emotion] = emotions_dict[emotion] + tweet[i]['emotions'][emotion]\n",
    "            # Categorize the hashtags by emotions.\n",
    "            if len(tweet[i]['hashtags'])>0 and len(tweet[i]['emotions'][emotion])>0:\n",
    "                hashtags_dict[emotion] = hashtags_dict[emotion] + tweet[i]['hashtags']\n",
    "    most_common_emotion_word = {}\n",
    "    most_common_hashtags = {}\n",
    "    emotions_count = []\n",
    "    # Count the total number of words across the tweets.\n",
    "    word_count = 0\n",
    "    total_count = reduce(lambda word_count , new : word_count + new['word_cnt'], tweet, 0)\n",
    "    # Get the most common words and hashtags in each emotions.\n",
    "    for emotion in EMOTIONS:\n",
    "        most_common_emotion_word[emotion] = most_common(emotions_dict[emotion])[:3]\n",
    "        most_common_hashtags[emotion] = most_common(hashtags_dict[emotion])[:3]\n",
    "        temp = (emotion, round(len(emotions_dict[emotion])/total_count*100,2))\n",
    "        emotions_count.append(temp)\n",
    "    # Sort the emotions by percentages.\n",
    "    emotions_count = sorted(emotions_count, key=lambda count:count[1], reverse=True)\n",
    "    return(emotions_count, most_common_emotion_word, most_common_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1IAB1LjtETQ"
   },
   "source": [
    "Define another function to display the information as a printed table (the function should take as an argument the data structure returned from the \"analysis\" function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKHM0H4OtETR",
    "outputId": "9c6fb9cb-81d1-45a8-9fa2-f098a049cafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION         % WORDS    EXAMPLE WORDS                       HASHTAGS\n",
      "positive        6.72%      learn, faculty, happy               #accesstoinfoday, #indigenouspeoplesday, #idealistfair\n",
      "trust           3.36%      school, faculty, happy              #indigenouspeoplesday, #diversity\n",
      "anticipation    2.76%      happy, top, ready                   #indigenouspeoplesday, #informatics, #info340\n",
      "joy             1.92%      happy, peace, deal                  #indigenouspeoplesday, #accesstoinfoday\n",
      "surprise        1.08%      deal, award, surprised              #suzzallolibrary, #nobrainer\n",
      "negative        0.96%      fall, rejection, outstanding        \n",
      "sadness         0.6%       fall, rejection, problem            \n",
      "disgust         0.48%      rejection, weird, finally           \n",
      "fear            0.48%      rejection, surprise, problem        \n",
      "anger           0.36%      rejection, disaster, involvement    #mlis\n"
     ]
    }
   ],
   "source": [
    "def format_table(analysis):\n",
    "    \"\"\"Print out a table to show the percentages of each emotions, the most common words and hashtags of that emotion.\"\"\"\n",
    "    # Header of the table\n",
    "    header = ['EMOTION', '% WORDS', 'EXAMPLE WORDS', 'HASHTAGS']\n",
    "    print(\"{:<15} {:<10} {:<35} {}\".format(*header))\n",
    "    comma = \", \"\n",
    "    hashtag = \", #\"\n",
    "    # Get the information needed from the input data\n",
    "    for i in range(len(EMOTIONS)): \n",
    "        emotion = analysis[0][i][0]\n",
    "        percentage = str(analysis[0][i][1])+\"%\"\n",
    "        words = comma.join(analysis[1][emotion])\n",
    "        if len(analysis[2][emotion])> 0:\n",
    "            hashtags = \"#\"+ hashtag.join(analysis[2][emotion])\n",
    "        else:\n",
    "            hashtags = \"\"\n",
    "        print(\"{:<15} {:<10} {:<35} {}\".format(emotion, percentage, words, hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJjLJf06tETT"
   },
   "source": [
    "## Getting Live Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQFduUnttETU"
   },
   "source": [
    "Define a function that takes in a Twitter username as an argument and then returns a list of dictionaries representing the tweets made by that user.\n",
    "\n",
    "Normally we could fetch this data by sending a request directly to the web service's API (e.g., to the the [statuses/user_timeline](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline) endpoint provided by the Twitter API at `https://api.twitter.com/1.1/statuses/user_timeline`). However, Twitter includes access controls so that only registered developers are allowed to send requests. Instead, we used a [proxy](https://en.wikipedia.org/wiki/Proxy) set up by a UW faculty, Joel Ross. Hence, we'll send a request to the url: \n",
    "`https://faculty.washington.edu/joelross/proxy/twitter/timeline/`\n",
    "instead of `https://api.twitter.com/1.1/statuses/user_timeline`, and it will redirect the request with the proper authentication to Twitter, and then give back whatever JSON Twitter's API responded with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZG-woABtETV"
   },
   "outputs": [],
   "source": [
    "def get_user(username):\n",
    "    \"\"\"Take in a Twitter username and output a structured tweet data of that account.\"\"\"\n",
    "    import requests, json\n",
    "    query_params = {\"screen_name\": username}\n",
    "    response = requests.get(\"https://faculty.washington.edu/joelross/proxy/twitter/timeline/\", params = query_params)\n",
    "    response_data = response.text\n",
    "    text_data = json.loads(response_data)\n",
    "    return(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MM_fO2q-tETW"
   },
   "source": [
    "Define a function that [prompts the user](https://docs.python.org/3/library/functions.html#input) for a Twitter username. The function should then fetch the tweets, and pass the returned tweet data into \"analyze\" and \"show\" functions in order to display your sentiment analysis of the user's timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duv0xSHttETX",
    "outputId": "c76352f6-701b-4eda-9e27-608c42f05390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Twitter account do you want to analyze? Dior\n",
      "EMOTION         % WORDS    EXAMPLE WORDS                       HASHTAGS\n",
      "positive        8.18%      creative, lover, passion            #diormagazine, #peterphilips, #miwakomatsu\n",
      "trust           3.69%      lover, passion, dance               #diormagazine, #peterphilips, #miwakomatsu\n",
      "joy             3.43%      lover, passion, love                #miwakomatsu, #yoonahn, #missdior\n",
      "anticipation    2.64%      lover, passion, calls               #diormagazine, #miwakomatsu, #yoonahn\n",
      "negative        1.32%      shot, calls, frenzied               #diormagazine, #missdior\n",
      "surprise        1.06%      inspired, shot, celebration         #diormagazine, #missdior, #peterphilips\n",
      "fear            0.79%      shot, frenzied, whirlwind           #missdior, #diormagazine\n",
      "anger           0.53%      shot, frenzied                      #diormagazine, #missdior\n",
      "sadness         0.26%      shot                                #diormagazine\n",
      "disgust         0.0%                                           \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from data.uw_ischool_sample import SAMPLE_TWEETS\n",
    "    from data.sentiments_nrc import SENTIMENTS, EMOTIONS\n",
    "    username = input(\"Which Twitter account do you want to analyze? \")\n",
    "    tweet = get_user(username)\n",
    "    analysis = analyze_tweets(tweet)\n",
    "    format_table(analysis)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tweeter_sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
